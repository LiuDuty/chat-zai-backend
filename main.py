# ============================================================
# SISTEMA DE CONVERSA INTELIGENTE (Z.ai + FastAPI)
# Contexto incremental + Timeout estendido + Ping Render Free
# CORS din√¢mico, configurado via vari√°vel de ambiente
# ============================================================

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import sqlite3, os, asyncio, random, httpx
from dotenv import load_dotenv
from contextlib import asynccontextmanager

# ------------------------------------------------------------
# 1Ô∏è‚É£ Configura√ß√µes
# ------------------------------------------------------------
load_dotenv()
API_KEY = os.getenv("ZAI_API_KEY")
API_URL = "https://api.z.ai/api/paas/v4/chat/completions"
DB_FILE = "conversas.db"
RENDER_URL = os.getenv("RENDER_URL")

# --- MUDAN√áA 1: Ler a URL do frontend da vari√°vel de ambiente ---
# Pega a URL do frontend a partir da vari√°vel de ambiente.
# Usamos um fallback (valor padr√£o) para o desenvolvimento local.
FRONTEND_URL = os.getenv("FRONTEND_URL", "http://localhost:4200")
print(f"üîç DEBUG 1: A vari√°vel de ambiente FRONTEND_URL √©: {FRONTEND_URL}")

SYSTEM_PROMPT = (
    "Voc√™ √© o KISS AZ-900, um assistente de estudos do exame Microsoft Azure Fundamentals (AZ-900). "
    "Responda de forma did√°tica, clara e coerente com o contexto da conversa."
)

# ------------------------------------------------------------
# 2Ô∏è‚É£ Banco de dados
# ------------------------------------------------------------
def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("""
        CREATE TABLE IF NOT EXISTS conversas (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            session_id TEXT NOT NULL,
            role TEXT,
            content TEXT,
            tipo_mensagem INTEGER
        )
    """)
    conn.commit()
    conn.close()

init_db()


def salvar_mensagem(session_id, role, content, tipo):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    if tipo == 2:
        c.execute("DELETE FROM conversas WHERE session_id=? AND tipo_mensagem=2", (session_id,))
        c.execute(
            "INSERT INTO conversas (session_id, role, content, tipo_mensagem) VALUES (?, ?, ?, 2)",
            (session_id, "system", content),
        )
    else:
        c.execute(
            "INSERT INTO conversas (session_id, role, content, tipo_mensagem) VALUES (?, ?, ?, 9)",
            (session_id, role, content),
        )
    conn.commit()
    conn.close()


def buscar_contexto(session_id):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT content FROM conversas WHERE session_id=? AND tipo_mensagem=2", (session_id,))
    r = c.fetchone()
    conn.close()
    return r[0] if r else ""

# ------------------------------------------------------------
# 3Ô∏è‚É£ Fun√ß√£o principal (ass√≠ncrona com timeout)
# ------------------------------------------------------------
async def atualizar_e_gerar_resposta(session_id: str, nova_mensagem: str):
    try:
        salvar_mensagem(session_id, "user", nova_mensagem, 9)
        contexto = buscar_contexto(session_id)

        prompt = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "system", "content": f"Contexto at√© agora:\n{contexto}"},
            {"role": "user", "content": nova_mensagem},
        ]

        headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
        timeout_config = httpx.Timeout(120.0)

        async with httpx.AsyncClient(timeout=timeout_config) as client:
            resp = await client.post(API_URL, json={"model": "glm-4.5-flash", "messages": prompt}, headers=headers)

        if resp.status_code != 200:
            return f"‚ùå Erro na API Z.ai: {resp.text}"

        data = resp.json()
        resposta = data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

        if not resposta:
            return "‚ö†Ô∏è Nenhuma resposta gerada pela API Z.ai."

        salvar_mensagem(session_id, "assistant", resposta, 9)

        novo_contexto = f"{contexto}\nUsu√°rio: {nova_mensagem}\nAssistente: {resposta}".strip()
        if len(novo_contexto) > 4000:
            novo_contexto = novo_contexto[-4000:]
        salvar_mensagem(session_id, "system", novo_contexto, 2)
        return resposta

    except Exception as e:
        return f"üí• Erro interno no backend: {str(e)}"

# ------------------------------------------------------------
# 4Ô∏è‚É£ FastAPI + CORS din√¢mico
# ------------------------------------------------------------
# --- MUDAN√áA 2: Usar um gerenciador de ciclo de vida (lifespan) ---
# Esta √© a forma moderna e recomendada de lidar com eventos de startup/shutdown.
@asynccontextmanager
async def lifespan(app: FastAPI):
    # C√≥digo de inicializa√ß√£o (startup)
    print("üöÄ Aplica√ß√£o est√° iniciando...")
    # Inicia a tarefa de ping em segundo plano
    ping_task = asyncio.create_task(ping_randomico())
    yield
    # C√≥digo de desligamento (shutdown)
    print("üõë Aplica√ß√£o est√° sendo desligada.")
    ping_task.cancel()
    try:
        await ping_task
    except asyncio.CancelledError:
        print("Tarefa de ping cancelada com sucesso.")


app = FastAPI(title="Z.ai Conversa Inteligente (Contexto Incremental + Timeout)", lifespan=lifespan)

# --- MUDAN√áA FINAL: Middleware para logar os headers de resposta ---
# Este middleware vai interceptar todas as respostas e imprimir seus headers no log.
# √â a nossa prova definitiva para saber se o header de CORS est√° sendo gerado pela aplica√ß√£o.
@app.middleware("http")
async def log_response_headers(request: Request, call_next):
    response = await call_next(request)
    # Imprime no console os headers que a aplica√ß√£o est√° enviando
    print(f"üåê DEBUG 3: Resposta para {request.url.method} {request.url.path} com headers: {dict(response.headers)}")
    return response
# -----------------------------------------------------------------

# --- MUDAN√áA 3: Usar a vari√°vel de ambiente na lista de origens permitidas ---
allowed_origins = [
    "http://localhost:4200",
    "http://127.0.0.1:4200",
    FRONTEND_URL,  # Agora a URL √© din√¢mica, vinda do .env
]

# --- MUDAN√áA 4: Adicionar um log para depura√ß√£o ---
print(f"üîç DEBUG 2: A lista final de origens permitidas para o CORS √©: {allowed_origins}")

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class Mensagem(BaseModel):
    texto: str
    session_id: str

@app.get("/")
async def home():
    return {"status": "‚úÖ API Z.ai ativa e mantendo contexto incremental."}

@app.post("/mensagem")
async def mensagem(request: Request):
    data = await request.json()
    texto = data.get("texto", "")
    session_id = data.get("session_id", "sessao")

    if not texto:
        return {"resposta": "Por favor, envie uma mensagem v√°lida."}

    resposta = f"Voc√™ disse: {texto}"
    return {"resposta": resposta}

@app.get("/contexto/{session_id}")
async def get_contexto(session_id: str):
    return {"contexto": buscar_contexto(session_id)}

# ------------------------------------------------------------
# 5Ô∏è‚É£ Ping aleat√≥rio (Render Free)
# ------------------------------------------------------------
async def ping_randomico():
    # IMPORTANTE: Certifique-se de que RENDER_URL no seu .env aponta para a URL correta do servi√ßo!
    # Ex: https://zai-backend-v2.onrender.com
    if not RENDER_URL:
        print("‚ö†Ô∏è RENDER_URL n√£o definido. Ping desativado.")
        return
    while True:
        try:
            async with httpx.AsyncClient() as client:
                await client.get(RENDER_URL)
                print("üîÅ Ping enviado para manter ativo.")
        except Exception as e:
            print(f"Erro no ping: {e}")
        await asyncio.sleep(random.randint(300, 600))